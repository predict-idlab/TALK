{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files = glob(\"./Data/*/*/*/*.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors = []\n",
    "proximities = []\n",
    "accelerations = []\n",
    "floors = []\n",
    "activities = []\n",
    "group = []\n",
    "for f in files:\n",
    "    if 'sensors' in f:\n",
    "        sensors.append(pd.read_csv(f, delimiter=';',encoding= 'unicode_escape'))\n",
    "    if 'proximity' in f:\n",
    "        proximities.append(pd.read_csv(f, delimiter=';',encoding= 'unicode_escape'))\n",
    "    if 'acceleration' in f:\n",
    "        hf = pd.read_csv(f, delimiter=';',encoding= 'unicode_escape')\n",
    "        hf['group'] = f.split('-')[-2]\n",
    "        accelerations.append(hf)\n",
    "    if 'floor' in f:\n",
    "        floors.append(pd.read_csv(f, delimiter=';',encoding= 'unicode_escape'))\n",
    "\n",
    "\n",
    "sf = pd.concat(sensors)\n",
    "sf.TIMESTAMP = pd.to_datetime(sf.TIMESTAMP)\n",
    "sf = sf.sort_values(\"TIMESTAMP\")\n",
    "pf = pd.concat(proximities)\n",
    "pf.TIMESTAMP = pd.to_datetime(pf.TIMESTAMP)\n",
    "wf = pd.concat(accelerations)\n",
    "wf.TIMESTAMP = pd.to_datetime(wf.TIMESTAMP)\n",
    "mf = pd.concat(floors)\n",
    "mf.TIMESTAMP = pd.to_datetime(mf.TIMESTAMP)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resample_value = '30s'\n",
    "\n",
    "with open('time-slots training.csv','r') as input_file:\n",
    "    data_str = input_file.read()\n",
    "    data_array = data_str.split(';;;;;;;;;;\\n;;;;;;;;;;\\n;;;;;;;;;;\\n') # Split on all instances of double new lines\n",
    "    for i, smaller_data in enumerate(data_array):\n",
    "        with open(f'train_file_{i}.txt','w') as new_data_file:\n",
    "            new_data_file.write(smaller_data)\n",
    "\n",
    "activities=[]\n",
    "for f in glob('train_file*.txt'):\n",
    "    activities.append(pd.read_csv(f,delimiter=';', skiprows=[0]).dropna(axis=1))\n",
    "\n",
    "temp = pd.read_csv('gt_labels.csv',delimiter=';').dropna(axis=1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "tdf = pd.DataFrame(mlb.fit_transform(temp['Activity_1'].apply(lambda x: [x])),columns=mlb.classes_).astype(bool)\n",
    "tdf['Timestamp'] = temp.Time\n",
    "tdf['test_data'] = True\n",
    "activities.append(tdf)\n",
    "\n",
    "df = pd.concat(activities).fillna(False).sort_values('Timestamp').reset_index(drop=True)\n",
    "df.Timestamp = pd.to_datetime(df.Timestamp)\n",
    "df = df.set_index('Timestamp', drop=True)\n",
    "df.loc[(~df).all(axis=1),'Idle'] = True\n",
    "#df = df.resample(resample_value).nearest(15).dropna()#.first().bfill().astype(bool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "group_samples = (sf[\"TIMESTAMP\"].dt.minute > (sf[\"TIMESTAMP\"].dt.minute.shift() + 5)).cumsum()\n",
    "grouped = sf.groupby(group_samples)\n",
    "group_list = [g.groupby(['TIMESTAMP', 'OBJECT'])['STATE'].aggregate('first').unstack().ffill() for k,g in grouped]\n",
    "sff = pd.concat(group_list)#.fillna('unkown')\n",
    "\n",
    "def check_fill(x):\n",
    "    #return 'Unknown'\n",
    "    if 'Close' in x.values:\n",
    "        return 'Close'\n",
    "    if 'Movement' in x.values:\n",
    "        return 'No Movement'\n",
    "    if 'Present' in x.values:\n",
    "        return 'No Present'\n",
    "    if 'Pressure' in x.values:\n",
    "        return 'No Pressure'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "fill_dct = {}\n",
    "for c in sff.columns:\n",
    "    if  check_fill(sff[c]):\n",
    "        fill_dct[c] = check_fill(sff[c])\n",
    "sff = sff.fillna(fill_dct)\n",
    "#sf.groupby(['TIMESTAMP', 'OBJECT'])['STATE'].aggregate('first').unstack().ffill(limit=3).fillna('unknown')#.pivot_table(values='STATE', columns='OBJECT')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time=\"2017-10-31 11:11:30\"\n",
    "pf[(pf.TIMESTAMP<(pd.Timestamp(time)+pd.Timedelta(resample_value)))&(pf.TIMESTAMP>(pd.Timestamp(time)))]\n",
    "\n",
    "total_f = pd.DataFrame(df.index)\n",
    "total_f.Timestamp = pd.to_datetime(total_f.Timestamp)\n",
    "total_f = total_f.sort_values(\"Timestamp\")\n",
    "\n",
    "sfff = pd.merge_asof(sff.reset_index(),total_f, right_on=\"Timestamp\", left_on=\"TIMESTAMP\", direction=\"backward\", tolerance=pd.Timedelta(resample_value)).dropna()#.fillna('Unknown')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import re\n",
    "g = Graph()\n",
    "g.parse(\"/Users/bramsteenwinckel/Documents/Projects/Protego/ucaml_cup/ucml.owl\")\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?room ?room_type ?floor\n",
    "WHERE {\n",
    "    ?room <https://saref.etsi.org/saref4bldg/isSpaceOf> ?floor .\n",
    "    ?room a ?room_type .\n",
    "    Filter(?room_type != <http://www.w3.org/2002/07/owl#NamedIndividual>) .\n",
    "    Filter(?room_type != <https://dahcc.idlab.ugent.be/Ontology/SensorsAndActuators/MultipurposeRoom>) .\n",
    "    Filter(?room_type != <https://dahcc.idlab.ugent.be/Ontology/SensorsAndActuators/Garage>) .\n",
    "    Filter(?room != <https://dahcc.idlab.ugent.be/Homelab/SensorsAndActuators/smallbedroom>) .\n",
    "}\"\"\"\n",
    "\n",
    "qres = g.query(query)\n",
    "rooms_types = {}\n",
    "for row in qres:\n",
    "    if '#' in row.room_type:\n",
    "        rooms_types[row.room.toPython()] = row.floor.split('#')[-1]+''+row.room_type.split('#')[-1]\n",
    "    else:\n",
    "        rooms_types[row.room.toPython()] = row.floor.split('#')[-1]+''+row.room_type.split('/')[-1]\n",
    "\n",
    "\n",
    "appliances = {}\n",
    "for room in rooms_types:\n",
    "    query = \"\"\"\n",
    "    SELECT ?appliance ?appliance_type ?sensor\n",
    "    WHERE {\n",
    "        ?appliance <https://saref.etsi.org/saref4bldg/isContainedIn> <%s> .\n",
    "        ?sensor <https://dahcc.idlab.ugent.be/Ontology/Sensors/analyseStateOf> ?appliance .\n",
    "        ?appliance a ?appliance_type .\n",
    "        Filter(?appliance_type != <http://www.w3.org/2002/07/owl#NamedIndividual>) .\n",
    "    }\"\"\"%(room)\n",
    "\n",
    "    qres = g.query(query)\n",
    "    for row in qres:\n",
    "        if room not in appliances:\n",
    "            appliances[room] = {}\n",
    "        tp = row.appliance_type.split('/')[-1].split('#')[-1]\n",
    "        if tp not in appliances[room]:\n",
    "            appliances[room][tp] = set()\n",
    "        appliances[room][tp].add((row.sensor.split('#')[-1],row.appliance.toPython()))\n",
    "#print(appliances[\"http://example.com/ucaml_cup#lab\"])\n",
    "result_appliances = {}\n",
    "for room in appliances:\n",
    "    result_appliances[room] = {}\n",
    "    for a in appliances[room]:\n",
    "        if len(appliances[room][a])==1:\n",
    "            result_appliances[room][list(appliances[room][a])[0][0]] = 'has'+a+\"State\"\n",
    "        else:\n",
    "            sensors = [re.sub('([a-zA-Z])', lambda x: x.groups()[0].upper(), x[1].split('#')[-1].replace('_',''), 1) for x in appliances[room][a]]\n",
    "            for i in range(len(sensors)):\n",
    "                s = sensors[i]\n",
    "                if 'has'+s+\"State\" in result_appliances[room]:\n",
    "                    result_appliances[room][list(appliances[room][a])[i][0]] = 'has'+s+\"State\"+str(len(result_appliances[room]))\n",
    "                else:\n",
    "                    result_appliances[room][list(appliances[room][a])[i][0]] = 'has'+s+\"State\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "uuid_event_map = {}\n",
    "uuid_room_map = {}\n",
    "uuid_map = {}\n",
    "\n",
    "def generate_obs_uuid(part):\n",
    "    if part not in uuid_map:\n",
    "        uuid_map[part] = 0\n",
    "    result = uuid_map[part]\n",
    "    uuid_map[part] += 1\n",
    "    return 'https://dahcc.idlab.ugent.be/Protego/'+part+'/obs'+str(result)\n",
    "\n",
    "def generate_room_uuid(room, part):\n",
    "    if part not in uuid_room_map:\n",
    "        uuid_room_map[part] = {}\n",
    "    if room not in uuid_room_map[part]:\n",
    "        uuid_room_map[part][room] = 0\n",
    "    result = uuid_room_map[part][room]\n",
    "    uuid_room_map[part][room] += 1\n",
    "    return 'https://dahcc.idlab.ugent.be/Protego/'+part+'/'+room+'/state'+str(result)\n",
    "\n",
    "def generate_event_uuid(part):\n",
    "    if part not in uuid_event_map:\n",
    "        uuid_event_map[part] = 0\n",
    "    result = uuid_event_map[part]\n",
    "    uuid_event_map[part] += 1\n",
    "    if result > 0:\n",
    "        return 'https://dahcc.idlab.ugent.be/Protego/'+part+'/event'+str(result), 'https://dahcc.idlab.ugent.be/Protego/'+part+'/event'+str(result-1)\n",
    "    else:\n",
    "        return 'https://dahcc.idlab.ugent.be/Protego/' + part + '/event' + str(\n",
    "            result), None\n",
    "\n",
    "def create_event(ff, part, time, prev_time):\n",
    "    with open('event_ucaml.nt', 'a') as f:\n",
    "        event, prev = generate_event_uuid(part)\n",
    "        if prev and (pd.Timestamp(time)-pd.Timestamp(prev_time))<=pd.Timedelta(resample_value):\n",
    "            f.write('<%s> <http://example.org/hasPrevious> <%s> .\\n'%(event, prev))\n",
    "\n",
    "        f.write('<%s> <https://saref.etsi.org/core/hasTimestamp> \"%s\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .\\n'%(event, time))\n",
    "\n",
    "        for a in [ff.index[i] for i, x in enumerate(ff.values) if x==True]:\n",
    "            f.write('<%s> <https://saref.etsi.org/core/hasActivity> \"%s\" .\\n' % (event, a))\n",
    "\n",
    "\n",
    "        for r in rooms_types:\n",
    "            room_state = generate_room_uuid(r.split('/')[-1].split('#')[-1],part)\n",
    "            f.write(\"<%s> <%s> <%s> .\\n\"%(event, \"https://dahcc.idlab.ugent.be/Protego/\"+rooms_types[r], room_state))\n",
    "\n",
    "\n",
    "            res_frame = sfff[sfff['Timestamp']==pd.Timestamp(time)]\n",
    "            if len(res_frame)>0:\n",
    "                prev_obs = {}\n",
    "                for e,row in res_frame.iterrows():\n",
    "                    for col in row.index:\n",
    "                        if col in result_appliances[r]:\n",
    "                            if row[col] != 'Unknown':\n",
    "                                obs = generate_obs_uuid(part)\n",
    "                                f.write(\"<%s> <%s> <%s> .\\n\"%(room_state, \"https://dahcc.idlab.ugent.be/Protego/\"+result_appliances[r][col], obs))\n",
    "                                f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#boolean> .\\n'%(obs, \"https://saref.etsi.org/core/has\"+row[col].replace(' ','')+\"Value\", \"true\" ))\n",
    "                                f.write('<%s> <%s> <%s> .\\n'%(obs, \"https://saref.etsi.org/core/measurementMadeBy\", \"http://example.com/ucaml_cup#\"+col))\n",
    "                                if col in prev_obs:\n",
    "                                    f.write('<%s> <%s> <%s> .\\n'%(obs, \"http://example.org/hasPreviousObs\", prev_obs[col]))\n",
    "                                prev_obs[col] = obs\n",
    "\n",
    "\n",
    "        wearable_state = generate_room_uuid('NearestObject',part)\n",
    "        f.write(\"<%s> <%s> <%s> .\\n\"%(event, \"https://dahcc.idlab.ugent.be/Protego/PersonNearestObject\", wearable_state))\n",
    "        res_frame = pf[(pf.TIMESTAMP<(pd.Timestamp(time)+pd.Timedelta(resample_value)))&(pf.TIMESTAMP>(pd.Timestamp(time)))]\n",
    "        res_frame = res_frame.groupby(['OBJECT']).agg({\"RSSI\": [np.mean, min, max]})\n",
    "        for i,row in res_frame.iterrows():\n",
    "            obs = generate_obs_uuid(part)\n",
    "            d = row.RSSI.values\n",
    "            o = 'near'+row.name.title().replace(' ','')+\"Observation\"\n",
    "            f.write(\"<%s> <%s> <%s> .\\n\"%(wearable_state, \"https://dahcc.idlab.ugent.be/Protego/\"+o, obs))\n",
    "            f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMeanValue\", d[0]))\n",
    "            f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMinValue\", d[1]))\n",
    "            f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMaxValue\", d[2]))\n",
    "\n",
    "        wearable_state = generate_room_uuid('Location',part)\n",
    "        f.write(\"<%s> <%s> <%s> .\\n\"%(event, \"https://dahcc.idlab.ugent.be/Protego/PersonLocation\", wearable_state))\n",
    "        res_frame = mf[(mf.TIMESTAMP<(pd.Timestamp(time)+pd.Timedelta(resample_value)))&(mf.TIMESTAMP>(pd.Timestamp(time)))]\n",
    "        if len(res_frame)>0:\n",
    "            for device, device_df in res_frame.groupby('DEVICE'):\n",
    "                obs = generate_obs_uuid(part)\n",
    "                o = 'has'+device.replace(',','')+'Observation'\n",
    "                vals = device_df['CAPACITANCE'].values\n",
    "\n",
    "                f.write(\"<%s> <%s> <%s> .\\n\"%(wearable_state, \"https://dahcc.idlab.ugent.be/Protego/\"+o, obs))\n",
    "                f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#boolean> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasValue\", \"true\"))\n",
    "                means = np.mean([[float(x) for x in v.split(',')] for v in vals], axis=0)\n",
    "                for i in range(len(means)):\n",
    "                    f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMeanValueZone\"+str(i), means[i]))\n",
    "                maxs = np.max([[float(x) for x in v.split(',')] for v in vals], axis=0)\n",
    "                for i in range(len(maxs)):\n",
    "                    f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMaxValueZone\"+str(i), maxs[i]))\n",
    "                mins = np.min([[float(x) for x in v.split(',')] for v in vals], axis=0)\n",
    "                for i in range(len(mins)):\n",
    "                    f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMinValueZone\"+str(i), mins[i]))\n",
    "                f.write('<%s> <%s> <%s> .\\n'%(obs, \"https://saref.etsi.org/core/measurementMadeBy\", \"http://example.com/ucaml_cup#Wearable\"))\n",
    "\n",
    "\n",
    "        wearable_state = generate_room_uuid('Accelerometer',part)\n",
    "        f.write(\"<%s> <%s> <%s> .\\n\"%(event, \"https://dahcc.idlab.ugent.be/Protego/PersonAccelerometer\", wearable_state))\n",
    "        res_frame = wf[(wf.TIMESTAMP<(pd.Timestamp(time)+pd.Timedelta(resample_value)))&(wf.TIMESTAMP>(pd.Timestamp(time)))]\n",
    "        if len(res_frame)>0:\n",
    "            f.write('<%s> <https://example.com/partOfGroup> \"%s\" .\\n' % (event, res_frame['group'].unique()[0]))\n",
    "        for metric in ['X','Y','Z']:\n",
    "            d = (res_frame[metric].mean(),res_frame[metric].min(),res_frame[metric].max())\n",
    "            obs = generate_obs_uuid(part)\n",
    "            o = 'has'+metric.replace('_',' ').replace('.',' ').title().replace(' ','')+\"Observation\"\n",
    "            f.write(\"<%s> <%s> <%s> .\\n\"%(wearable_state, \"https://dahcc.idlab.ugent.be/Protego/\"+o, obs))\n",
    "            f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMeanValue\", d[0]))\n",
    "            f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMinValue\", d[1]))\n",
    "            f.write('<%s> <%s> \"%s\"^^<http://www.w3.org/2001/XMLSchema#float> .\\n'%(obs, \"https://dahcc.idlab.ugent.be/Protego/hasMaxValue\", d[2]))\n",
    "            f.write('<%s> <%s> <%s> .\\n'%(obs, \"https://saref.etsi.org/core/measurementMadeBy\", \"http://example.com/ucaml_cup#Wearable\"))\n",
    "\n",
    "##################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prev = None\n",
    "for i,event in tqdm(df.iterrows(), total=len(df)):\n",
    "    create_event(event, \"Mario\", i, prev)\n",
    "    prev = i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}